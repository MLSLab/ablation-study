{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45cb6922",
   "metadata": {},
   "source": [
    "An ablation study in the context of neural networks (and machine learning in general) is a technique used to understand the effect of different components or features of the model on its performance. It involves systematically removing (\"ablating\") parts of the model (such as layers, nodes, or inputs) and assessing how each removal affects the model's performance. This process helps to isolate the impact of specific components and better understand their role in the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192aa1f",
   "metadata": {},
   "source": [
    "Let's create a simple code for an ablation study using Python and Keras library. We'll use Pima Indians Diabetes Database from UCI Machine Learning Repository.\n",
    "\n",
    "Here's an example how to do an ablation study on the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e6da67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(url, names=names)\n",
    "dataset = dataframe.values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "dataset[:,:8] = scaler.fit_transform(dataset[:,:8])\n",
    "\n",
    "# Split into input (X) and output (Y) variables\n",
    "X = dataset[:,:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f961fb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (614,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710b9d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154, 8), (154,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf4233",
   "metadata": {},
   "source": [
    "### Ablation on inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e46b80",
   "metadata": {},
   "source": [
    "Ablation on inputs: This involves removing one or more of the input features and examining the effect on performance. For example, we might start by training and testing the model with all 8 features, then removing the 'Diabetes pedigree function' feature and retraining/retesting the model, and then comparing the performances. If the performance decreases significantly, this suggests that the 'Diabetes pedigree function' is an important feature for the prediction task. We could then repeat this process for each of the 8 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f42ca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with all features: 75.97\n",
      "Accuracy without feature preg: 74.03\n",
      "Accuracy without feature plas: 69.48\n",
      "Accuracy without feature pres: 75.32\n",
      "Accuracy without feature skin: 74.03\n",
      "Accuracy without feature test: 75.32\n",
      "Accuracy without feature mass: 75.97\n",
      "Accuracy without feature pedi: 75.97\n",
      "Accuracy without feature age: 75.32\n"
     ]
    }
   ],
   "source": [
    "# Define and compile the model\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train model with all features\n",
    "model = create_model(8)\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy with all features: %.2f' % (accuracy*100))\n",
    "\n",
    "# Now, we do an ã…¡ on each feature\n",
    "for i in range(8):\n",
    "    # Remove one feature\n",
    "    X_train_ablation = np.delete(X_train, i, axis=1)\n",
    "    X_test_ablation = np.delete(X_test, i, axis=1)\n",
    "    \n",
    "    # Train model with one less feature\n",
    "    model_ablation = create_model(7)\n",
    "    model_ablation.fit(X_train_ablation, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    _, accuracy_ablation = model_ablation.evaluate(X_test_ablation, y_test, verbose=0)\n",
    "    print('Accuracy without feature %s: %.2f' % (names[i], accuracy_ablation*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf18c2",
   "metadata": {},
   "source": [
    "Now you can see how the performance of your model changes when you remove each feature individually.\n",
    "\n",
    "As you can see, the model's performance (measured in accuracy) drops the most when you remove the 'plas' feature. This suggests that 'plas' (Plasma glucose concentration a 2 hours in an oral glucose tolerance test) is an important feature for predicting diabetes in this dataset.\n",
    "\n",
    "However, removing other features, such as 'pres', 'test', 'mass', 'pedi', and 'age' doesn't significantly decrease the model's performance, which suggests that these features might not be as critical to the model's predictions, at least in the current configuration.\n",
    "\n",
    "Keep in mind that these are just interpretations based on this specific model configuration and this specific training/test split. Different model architectures, hyperparameters, or training/test splits might lead to different results.\n",
    "\n",
    "Furthermore, this doesn't mean that the features that lead to smaller drops in performance are unimportant. They could be interacting with other features in ways that this analysis doesn't capture. It is also possible that other model architectures could leverage these features more effectively.\n",
    "\n",
    "But overall, this is a good way to get a basic understanding of which features your model is relying on the most. This can be especially useful when you're trying to understand a complex model or when you're deciding which features to collect in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074baa3",
   "metadata": {},
   "source": [
    "### Ablation on layers/nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fc287",
   "metadata": {},
   "source": [
    "Ablation on layers/nodes: This involves removing one or more layers or nodes in the network and examining the effect on performance. For example, we might start by training and testing the model with the full architecture, then removing one node from the hidden layer and retraining/retesting the model, and then comparing the performances. If the performance decreases significantly, this suggests that the removed node was doing important work in the prediction task. We could then repeat this process for each node in the hidden layer, or even try removing the entire hidden layer itself to see the effect on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a55e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with all nodes: 75.32\n",
      "Accuracy with 16 nodes: 76.62\n",
      "Accuracy with 15 nodes: 75.97\n",
      "Accuracy with 14 nodes: 74.03\n",
      "Accuracy with 13 nodes: 74.68\n",
      "Accuracy with 12 nodes: 75.32\n",
      "Accuracy with 11 nodes: 72.08\n",
      "Accuracy with 10 nodes: 73.38\n",
      "Accuracy with 9 nodes: 75.97\n",
      "Accuracy with 8 nodes: 76.62\n",
      "Accuracy with 7 nodes: 75.32\n",
      "Accuracy with 6 nodes: 72.08\n",
      "Accuracy with 5 nodes: 74.03\n",
      "Accuracy with 4 nodes: 72.73\n",
      "Accuracy with 3 nodes: 76.62\n",
      "Accuracy with 2 nodes: 71.43\n",
      "Accuracy with 1 nodes: 76.62\n"
     ]
    }
   ],
   "source": [
    "# Define and compile the model\n",
    "def create_model(input_dim, hidden_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_dim, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train model with all nodes\n",
    "model = create_model(8, 16)\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy with all nodes: %.2f' % (accuracy*100))\n",
    "\n",
    "# Now, we do an ablation study on each node\n",
    "for i in range(16, 0, -1):\n",
    "    # Train model with one less node\n",
    "    model_ablation = create_model(8, i)\n",
    "    model_ablation.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    _, accuracy_ablation = model_ablation.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Accuracy with %d nodes: %.2f' % (i, accuracy_ablation*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e9b52",
   "metadata": {},
   "source": [
    "It seems like your model is quite robust with respect to the number of nodes in the hidden layer, given that the accuracy doesn't change dramatically when reducing the nodes. There's some variability in the performance, but overall, the accuracy remains relatively consistent across different numbers of nodes.\n",
    "\n",
    "Notably, the performance doesn't drop drastically even when you go down to just one node. This might indicate that the task is relatively simple and can be solved with a smaller model.\n",
    "\n",
    "However, you might notice some \"jumps\" in accuracy when changing the number of nodes. This can be due to several reasons:\n",
    "\n",
    "The optimization landscape of neural networks is highly non-convex and changing the architecture of the network (like the number of nodes) might lead to different local minima. These differences might be small, but they can lead to noticeable changes in performance.\n",
    "\n",
    "The initialization of the network weights is random, and different initializations can lead to different results. This can introduce some variability in the results, even when the architecture and the data are the same.\n",
    "\n",
    "It's also worth mentioning that even though the model with just one node performs almost as well as the full model on this test set, it might not generalize as well to new data. The model with more nodes has a higher capacity and might be able to learn more complex patterns in the data, which could be useful when facing new, unseen data.\n",
    "\n",
    "As always, it's important to consider these results in the context of your specific task and data. Different tasks might have different optimal model sizes and the best way to find the right model size is often through experimentation and validation on a separate validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efeea9",
   "metadata": {},
   "source": [
    "By performing an ablation study in this manner, we can gain valuable insights into which features are most important for the prediction task, and how much complexity is necessary in the neural network architecture for optimal performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
